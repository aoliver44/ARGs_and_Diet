{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe5fc43",
   "metadata": {},
   "source": [
    "### Load up required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b095f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Loading modules...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "print('##########\\nLoading modules...')\n",
    "\n",
    "import os, sys, getopt, datetime, multiprocessing\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, StratifiedKFold, cross_validate, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,label_binarize\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, plot_confusion_matrix, roc_curve, plot_roc_curve\n",
    "from sklearn.metrics import make_scorer, accuracy_score, balanced_accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score, plot_precision_recall_curve, precision_recall_curve, auc\n",
    "from sklearn.inspection import permutation_importance\n",
    "from pickle import load, dump\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap \n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import joblib\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0649a58b",
   "metadata": {},
   "source": [
    "### Set working directory and random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6e3c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "Working directory is /home/Python_code\n"
     ]
    }
   ],
   "source": [
    "## set working directory\n",
    "workdir = os.getcwd()\n",
    "print('#########\\nWorking directory is {}'.format(workdir))\n",
    "\n",
    "## set seed\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec79e0",
   "metadata": {},
   "source": [
    "### Tell program where to look for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce84eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dimensions of data are (140, 158)\n"
     ]
    }
   ],
   "source": [
    "X_path = \"../RF_models/diet-life_input_bi.csv\"\n",
    "X_in = pd.read_csv(X_path)\n",
    "X_in = X_in.sort_index(axis = 0)\n",
    "#print(X_in.head())\n",
    "print('\\n Dimensions of data are {}'.format(X_in.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15733e3b",
   "metadata": {},
   "source": [
    "### Tell program what column is the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef6ca9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The class we care about is: **cluster**\n",
      "Dropping cluster from the input data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_label= \"cluster\"\n",
    "print('\\n\\nThe class we care about is: **{}**'.format(y_label))\n",
    "print('Dropping {} from the input data\\n'.format(y_label))\n",
    "y = X_in[[y_label]]\n",
    "X_in = X_in.drop(y_label, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b6c20",
   "metadata": {},
   "source": [
    "### Make test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c12bb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_in, y, random_state = 1, test_size = 0.3, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336fc29",
   "metadata": {},
   "source": [
    "### Define the cross validation strategy & pipeline & hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e0996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inner cross validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "## select k-best features\n",
    "#feat_sel = SelectKBest(mutual_info_classif)\n",
    "\n",
    "## pipeline\n",
    "pipeline_rf = Pipeline([\n",
    "    #('mutual_info', feat_sel),\n",
    "    ('model', RandomForestClassifier(random_state=1, oob_score=True, class_weight='balanced'))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177fb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the hyperparameter search space\n",
    "space = dict()\n",
    "space['model__n_estimators'] = np.arange(500,1500,50)\n",
    "space['model__min_samples_split'] = np.arange(2,5,1)\n",
    "space['model__max_features'] = np.arange(0.2,0.8,0.05)\n",
    "space['model__max_samples'] = np.arange(0.1, 1, 0.05)\n",
    "#space['model__criterion'] = ['gini', 'entropy']\n",
    "#space['mutual_info__k'] = np.arange(10, 360, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a987e1",
   "metadata": {},
   "source": [
    "### Tune the hyperparmeters with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4435f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scoring = {'f1_macro','balanced_accuracy'} \n",
    "refit = 'balanced_accuracy'\n",
    "search = RandomizedSearchCV(estimator = pipeline_rf, n_iter=2000, \n",
    "                      param_distributions = space, scoring=scoring, \n",
    "                      cv=cv, refit=refit, return_train_score = True, n_jobs = 24, random_state=1)\n",
    "search.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb8a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:\n",
      " Pipeline(steps=[('model',\n",
      "                 RandomForestClassifier(class_weight='balanced',\n",
      "                                        max_features=0.5499999999999999,\n",
      "                                        max_samples=0.8000000000000002,\n",
      "                                        min_samples_split=3, n_estimators=950,\n",
      "                                        oob_score=True, random_state=1))])\n",
      "Best params:\n",
      " {'model__n_estimators': 950, 'model__min_samples_split': 3, 'model__max_samples': 0.8000000000000002, 'model__max_features': 0.5499999999999999}\n"
     ]
    }
   ],
   "source": [
    "## OR load up previously saved file\n",
    "with open('../RF_models/diet_life_bi.pkl', 'rb') as f:\n",
    "    search = pickle.load(f)\n",
    "\n",
    "rf_final_pipe = search.best_estimator_\n",
    "print(\"Best model:\\n\", search.best_estimator_)\n",
    "print(\"Best params:\\n\", search.best_params_)\n",
    "search.best_estimator_.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299185ef",
   "metadata": {},
   "source": [
    "### Analyze performance of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79221593-43ab-4814-af83-fdd0abf6928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the confusion matrix on the test data\n",
    "plot_confusion_matrix(rf_final_pipe, x_test, y_test)\n",
    "\n",
    "## print OOB score on test data\n",
    "print(\"OOB score:\",search.best_estimator_.named_steps['model'].oob_score_)\n",
    "\n",
    "## print balanced accuracy score on test data\n",
    "## The balanced accuracy in binary and multiclass classification problems \n",
    "## to deal with imbalanced datasets. It is defined as the average of recall obtained on each class. \n",
    "yhat = rf_final_pipe.predict_proba(x_test)\n",
    "preds = [1 if yhat[i][1] > .5 else 0 for i in range(len(yhat))]\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, preds))\n",
    "\n",
    "## print the F1-score (mix between precision and recall)\n",
    "print(\"f1_score (macro):\", f1_score(y_test, preds, average='macro'))\n",
    "\n",
    "## print the Cohen Kappa score\n",
    "print(\"Cohen's kappa:\", cohen_kappa_score(y_test, preds))\n",
    "\n",
    "## plot roc curve\n",
    "plot_roc_curve(rf_final_pipe, x_test, y_test, pos_label=0)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "## plot pr curve\n",
    "plot_precision_recall_curve(rf_final_pipe, x_test, y_test, pos_label=0)\n",
    "precision, recall, _ = precision_recall_curve(y_test, preds)\n",
    "auc_score = auc(recall, precision)\n",
    "print('PR AUC: %.3f' % auc_score)\n",
    "\n",
    "## roc curve: multiclass\n",
    "#print(\"ROC AUC:\", roc_auc_score(y_test, yhat, multi_class='ovr', average='weighted'))\n",
    "\n",
    "## roc curve: binary\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, yhat[:,1]))\n",
    "\n",
    "## classification report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b0d5a",
   "metadata": {},
   "source": [
    "### Modify probabilities due to class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine a new cutoff for classification (not 0.5 anymore!)\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "probs = yhat[:, 1]\n",
    "thresholds = np.arange(0,1,0.001)\n",
    "\n",
    "## use Cohen's Kappa (or F1 or ROC AUC or Balanced Accuracy)\n",
    "#scores = [f1_score(y_test, to_labels(probs, t), average='macro') for t in thresholds]\n",
    "#scores = [balanced_accuracy_score(y_test, to_labels(probs, t)) for t in thresholds]\n",
    "#scores = [roc_auc_score(y_test, to_labels(probs, t)) for t in thresholds]\n",
    "scores = [cohen_kappa_score(y_test, to_labels(probs, t)) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure out the highest score for all probability thresholds (0-1)\n",
    "ix = np.argmax(scores)\n",
    "print(f'Threshold = {thresholds[ix]}, Kappa = {scores[ix]}')\n",
    "new_threshold = thresholds[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change the probability threshold\n",
    "new_preds = [1 if yhat[i][1] > new_threshold else 0 for i in range(len(yhat))]\n",
    "print(new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyze classifier performance with new probability threshold\n",
    "print(\"New Confusion Matrix:\\n\", confusion_matrix(y_test, new_preds))\n",
    "print(\"f1_score (macro):\", f1_score(y_test, new_preds, average='macro'))\n",
    "print(\"Balanced Accuracy:\", f1_score(y_test, new_preds))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, new_preds))\n",
    "print(\"Cohen's Kappa:\", cohen_kappa_score(y_test, new_preds))\n",
    "precision, recall, _ = precision_recall_curve(y_test, new_preds)\n",
    "auc_score = auc(recall, precision)\n",
    "print('PR AUC: %.3f' % auc_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc501a",
   "metadata": {},
   "source": [
    "### Analyze Feature Importance: SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out shap values\n",
    "shap_values = shap.TreeExplainer(rf_final_pipe['model']).shap_values(X_in)\n",
    "shap.summary_plot(shap_values, X_in, plot_type=\"bar\", max_display=10, show=False)\n",
    "#plt.savefig('/home/Figures/shap_figures/diet_life_New_covariates.pdf',format='pdf', dpi=1000, bbox_inches='tight')\n",
    "#plt.clf()\n",
    "#shap.summary_plot(shap_values[1], X_in, plot_type = 'dot', max_display= 20, show=False)\n",
    "#plt.savefig('/home/Figures/shap_figures/diet-lifestyle_input_bi_f1_400iter.pdf',format='pdf', dpi=1000, bbox_inches='tight')\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aad06e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Output raw shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer_feature_names(columnTransformer):\n",
    "\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in columnTransformer.transformers_:\n",
    "        if name!='remainder':\n",
    "            for i in pipe:\n",
    "                trans_features = []\n",
    "                if hasattr(i,'categories_'):\n",
    "                    trans_features.extend(i.get_feature_names(features))\n",
    "                else:\n",
    "                    trans_features = features\n",
    "            output_features.extend(trans_features)\n",
    "\n",
    "    return output_features\n",
    "\n",
    "#transform the x data \n",
    "mod = rf_final_pipe['model']\n",
    "\n",
    "preds = mod.predict_proba(X_in)\n",
    "feature_names = X_in.columns\n",
    "print(feature_names)\n",
    "shap_values = shap.TreeExplainer(mod).shap_values(X_in)\n",
    "explainer = shap.TreeExplainer(mod)\n",
    "\n",
    "##row sums for subj 0 \n",
    "print(shap_values[0][0].sum(0))\n",
    "\n",
    "print(preds[0,0]) #this is the prediction for subj 0, class 0 \n",
    "print(explainer.expected_value[0]) #expected valuef or class 0\n",
    "print(preds[0,0] - explainer.expected_value[0]) #the diff between the model output and the expected value. should match the above value\n",
    "\n",
    "\n",
    "shap_values0 = pd.DataFrame(shap_values[0], columns = feature_names, index = X_in.index)\n",
    "shap_values1 = pd.DataFrame(shap_values[1], columns = feature_names, index = X_in.index)\n",
    "#shap_values2 = pd.DataFrame(shap_values[2], columns = feature_names, index = X_in.index)\n",
    "\n",
    "#print(list(shap_values0.columns))\n",
    "\n",
    "#file0 = \"diet-life_high-low_shapvals-NEW.csv\"\n",
    "file1 = \"diet-life_high-low_shapvals-NEW.csv\"\n",
    "#file2 = \"diet-life_high-low_class2_shapvals-NEW.csv\"\n",
    "#file_raw = \"diet-life_bi_raw-NEW.csv\"\n",
    "#file2 = \"diet-life_input_bi_class2_shapvals.csv\"\n",
    "#path = \"../machine_learning/new_dataset_models/shap_values/\"\n",
    "\n",
    "path = \"\"\n",
    "#shap_values0.to_csv(path + file0, index = True)\n",
    "shap_values1.to_csv(path + file1, index = True)\n",
    "#shap_values2.to_csv(path + file2, index = True)\n",
    "#X_in.to_csv(path + file_raw, index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011403f",
   "metadata": {},
   "source": [
    "### Save model as pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f33ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save CHECK FILE NAME!!\n",
    "#import pickle\n",
    "#with open('diet_life_high-low.pkl','wb') as f:\n",
    "#    pickle.dump(search,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_in.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7514b6-7e5f-45ee-8f7a-0d76455ad213",
   "metadata": {},
   "source": [
    "### Run the data through DUMMY classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e02870",
   "metadata": {},
   "outputs": [],
   "source": [
    "## running the dummy classifier\n",
    "clf_dummy = DummyClassifier(random_state=1, strategy='most_frequent')\n",
    "dummy_fit = clf_dummy.fit(x_train, y_train)\n",
    "y_pred_dummy = clf_dummy.predict(x_test)\n",
    "\n",
    "## Analyze dummy classifier performance with new probability threshold\n",
    "print(\"New Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dummy))\n",
    "print(\"f1_score (macro):\", f1_score(y_test, y_pred_dummy, average='macro'))\n",
    "print(\"Balanced Accuracy:\", f1_score(y_test, y_pred_dummy))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_dummy, average= 'weighted'))\n",
    "print(\"Cohen's Kappa:\", cohen_kappa_score(y_test, y_pred_dummy))\n",
    "\n",
    "## plot roc curve\n",
    "plot_roc_curve(dummy_fit, x_test, y_test)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "## plot the confusion matrix on the test data\n",
    "plot_confusion_matrix(dummy_fit, x_test, y_test)\n",
    "\n",
    "## roc curve: multiclass\n",
    "#print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_dummy, multi_class='ovr', average='weighted'))\n",
    "\n",
    "## pr curve\n",
    "plot_precision_recall_curve(dummy_fit, x_test, y_test, pos_label=1)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_dummy)\n",
    "auc_score = auc(recall, precision)\n",
    "print('No Skill PR AUC: %.3f' % auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73265e2-4c80-40b1-9016-9ed043984544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
